{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1713891497657,
     "user": {
      "displayName": "Rahat Parvej",
      "userId": "17759206363434202158"
     },
     "user_tz": -360
    },
    "id": "mM1d3wp5ll8J"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_training_samples(image_folder, annotation_folder, target_size):\n",
    "    training_samples = []\n",
    "\n",
    "    for image_file in os.listdir(image_folder):\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        annotation_path = os.path.join(annotation_folder, image_file.replace(\".jpg\", \".txt\"))\n",
    "        real_img = cv2.imread(image_path)\n",
    "        img = cv2.cvtColor(real_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        with open(annotation_path, 'r') as annotation_file:\n",
    "            lines = annotation_file.readlines()\n",
    "\n",
    "            for line in lines:\n",
    "                data = line.strip().split()\n",
    "                class_label = int(data[0])\n",
    "                x_center, y_center, width, height = map(float, data[1:5])\n",
    "\n",
    "\n",
    "                # Convert YOLO format to (x, y, w, h)\n",
    "                x = int((x_center - width / 2) * img.shape[1])\n",
    "                y = int((y_center - height / 2) * img.shape[0])\n",
    "                w = int(width * img.shape[1])\n",
    "                h = int(height * img.shape[0])\n",
    "\n",
    "                # Read the image and crop the region defined by the bounding box\n",
    "\n",
    "                # cropped_region = img[y:y+h, x:x+w]\n",
    "                cropped_region = img[max(y, 0):min(y+h, img.shape[0]), max(x, 0):min(x+w, img.shape[1])]\n",
    "\n",
    "                # Resize the cropped region to the target size\n",
    "                resized_cropped_region = cv2.resize(cropped_region, target_size)\n",
    "\n",
    "                # Normalize pixel values to [0, 1]\n",
    "                normalized_cropped_region = resized_cropped_region / 255.0\n",
    "\n",
    "                # Append the training sample along with its class label\n",
    "                training_samples.append((normalized_cropped_region, class_label))\n",
    "\n",
    "    return training_samples\n",
    "\n",
    "image_folder = 'dataset/mvcheck'\n",
    "annotation_folder = 'dataset/labels'\n",
    "\n",
    "\n",
    "# xception data\n",
    "\n",
    "xception_size = (299, 299)\n",
    "\n",
    "xception_training_samples = create_training_samples(image_folder, annotation_folder, xception_size)\n",
    "\n",
    "xception_X_test, xception_y_test = zip(*xception_training_samples)\n",
    "xception_X_test= np.array(xception_X_test)\n",
    "xception_y_test =np.array(xception_y_test)\n",
    "\n",
    "#alexnet data\n",
    "alexnet_size = (227, 227)\n",
    "\n",
    "alexnet_training_samples = create_training_samples(image_folder, annotation_folder, alexnet_size)\n",
    "\n",
    "alexnet_X_train, alexnet_y_train = zip(*alexnet_training_samples)\n",
    "\n",
    "\n",
    "alexnet_X_train =np.array(alexnet_X_train)\n",
    "alexnet_y_train =np.array(alexnet_y_train)\n",
    "\n",
    "#resnet data\n",
    "resnet_size = (224, 224)\n",
    "\n",
    "resnet_training_samples = create_training_samples(image_folder, annotation_folder, resnet_size)\n",
    "\n",
    "resnet_X_train, resnet_y_train = zip(*resnet_training_samples)\n",
    "\n",
    "\n",
    "resnet_X_train= np.array(resnet_X_train)\n",
    "resnet_y_train =np.array(resnet_y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = load_model('models/alexnet_16batch_30epoch.h5')\n",
    "inception = load_model('models/inception_16batch_10epoch.h5')\n",
    "resnet = load_model('models/resnet_16batch_30epoch.h5')\n",
    "xception = load_model('models/xception_16batch_30epoch.h5')\n",
    "vgg = load_model('models/vgg_16batch_30epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3448,
     "status": "ok",
     "timestamp": 1713889071197,
     "user": {
      "displayName": "Rahat Parvej",
      "userId": "17759206363434202158"
     },
     "user_tz": -360
    },
    "id": "CCS3VzRA68zB",
    "outputId": "b8cbdadf-746f-4feb-90ed-a5bd85ba05ba"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "resnet_score = resnet.evaluate(resnet_X_train, resnet_y_train)\n",
    "vgg_score = vgg.evaluate(resnet_X_train, resnet_y_train)\n",
    "alexnet_score = alexnet.evaluate(alexnet_X_train, alexnet_y_train)\n",
    "xception_score= xception.evaluate(xception_X_test,xception_y_test)\n",
    "inception_score = inception.evaluate(xception_X_test, xception_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6991,
     "status": "ok",
     "timestamp": 1713889085323,
     "user": {
      "displayName": "Rahat Parvej",
      "userId": "17759206363434202158"
     },
     "user_tz": -360
    },
    "id": "TqD164m0_xvy",
    "outputId": "a586e29d-e641-485e-9215-b2988dfd4b1a"
   },
   "outputs": [],
   "source": [
    "resnet_pred= resnet.predict(resnet_X_train)\n",
    "vgg_pred= vgg.predict(resnet_X_train)\n",
    "xception_pred=xception.predict(xception_X_test)\n",
    "inception_pred= inception.predict(xception_X_test)\n",
    "alexnet_pred=alexnet.predict(alexnet_X_train)\n",
    "\n",
    "modified_resnet_pred = np.where(resnet_pred < 0.5, 0, 1)\n",
    "modified_vgg_pred = np.where(vgg_pred < 0.5, 0, 1)\n",
    "modified_xception_pred = np.where(xception_pred < 0.5, 0, 1)\n",
    "modified_inception_pred = np.where(inception_pred < 0.5, 0, 1)\n",
    "modified_alexnet_pred = np.where(alexnet_pred < 0.5, 0, 1)\n",
    "\n",
    "\n",
    "#majoriti prediction choice\n",
    "from collections import Counter\n",
    "\n",
    "result = []\n",
    "\n",
    "for i in range(len(modified_alexnet_pred)):\n",
    "    counts = Counter([modified_resnet_pred[i][0],modified_vgg_pred[i][0], modified_xception_pred[i][0],modified_inception_pred[i][0],modified_alexnet_pred[i][0]])\n",
    "    #Counter(0,0,1,1,0)\n",
    "    most_common = counts.most_common(1)[0][0]\n",
    "    result.append([most_common])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1711897994856,
     "user": {
      "displayName": "Rahat Parvej",
      "userId": "17759206363434202158"
     },
     "user_tz": -360
    },
    "id": "U7cXT3zOCWQ1",
    "outputId": "c02c877b-bb80-48d4-dc49-89a7fdf99580"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, precision_score,recall_score\n",
    "\n",
    "# For classification\n",
    "accuracy = accuracy_score(xception_y_test, result)\n",
    "precision=precision_score(xception_y_test, result)\n",
    "recall=recall_score(xception_y_test, result)\n",
    "print(accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(xception_y_test, result, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1711898476546,
     "user": {
      "displayName": "Rahat Parvej",
      "userId": "17759206363434202158"
     },
     "user_tz": -360
    },
    "id": "dOP9JU73-DU0",
    "outputId": "a58cbfa9-b1cc-446a-8256-bdae6c5c452a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# For classification\n",
    "accuracy = accuracy_score(xception_y_test, result)\n",
    "\n",
    "# For regression\n",
    "mae = mean_absolute_error(xception_y_test, result)\n",
    "mse = mean_squared_error(xception_y_test, result)\n",
    "rmse = mean_squared_error(xception_y_test, result, squared=False)  # RMSE\n",
    "r_squared = r2_score(xception_y_test, result)\n",
    "print('Mean Absolute Error:',mae, \"Mean Squared Error:\",mse, \"Root Mean Squared Error:\",rmse, \"R2 Score:\", r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ksJ2yHGAvOS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bai_QUKoyQly"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "executionInfo": {
     "elapsed": 13382,
     "status": "ok",
     "timestamp": 1713895813772,
     "user": {
      "displayName": "Rahat Parvej",
      "userId": "17759206363434202158"
     },
     "user_tz": -360
    },
    "id": "Xfxhr51n74Et",
    "outputId": "d6b9483f-0e00-4335-dc51-df86d6dfb662"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the trained Xception model\n",
    "model_path = 'models/vgg_16batch_30epoch.h5'  # Replace with your model path\n",
    "xception = load_model(model_path)\n",
    "\n",
    "# Read the image and its annotation\n",
    "image_path = 'dataset/images/IMG_20240125_151732.jpg'  # Replace with your image path\n",
    "annotation_path = 'dataset/labels/IMG_20240125_151732.txt'  # Replace with your annotation path\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "original_img = img.copy()  # Make a copy of the original image for visualization\n",
    "\n",
    "# Read annotations and perform object localization\n",
    "with open(annotation_path, 'r') as annotation_file:\n",
    "    lines = annotation_file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        data = line.strip().split()\n",
    "\n",
    "        class_label = int(data[0])\n",
    "        x_center, y_center, width, height = map(float, data[1:5])\n",
    "\n",
    "        # Convert YOLO format to (x, y, w, h)\n",
    "        x = int((x_center - width / 2) * img.shape[1])\n",
    "        y = int((y_center - height / 2) * img.shape[0])\n",
    "        w = int(width * img.shape[1])\n",
    "        h = int(height * img.shape[0])\n",
    "\n",
    "        # Crop the region defined by the bounding box\n",
    "        # cropped_region = img[y:y+h, x:x+w]\n",
    "        cropped_region = img[max(y, 0):min(y+h, img.shape[0]), max(x, 0):min(x+w, img.shape[1])]\n",
    "\n",
    "        # Resize the cropped region to the target size (227, 227)\n",
    "        resized_cropped_region = cv2.resize(cropped_region, (227, 227))\n",
    "\n",
    "        # Normalize pixel values to [0, 1]\n",
    "        normalized_cropped_region = resized_cropped_region / 255.0\n",
    "\n",
    "        # Predict the class label for the cropped region\n",
    "        prediction = xception.predict(np.expand_dims(normalized_cropped_region, axis=0))\n",
    "\n",
    "        predicted_class = int(np.round(prediction)[0][0])\n",
    "        if predicted_class==0:\n",
    "            pclass='Paddy'\n",
    "        else:\n",
    "            pclass='Weed'\n",
    "\n",
    "        # Draw bounding box and label on the original image\n",
    "\n",
    "        cv2.rectangle(original_img, (x, y), (x+w, y+h), (0, 255, 0), 5)\n",
    "        cv2.putText(original_img, f\" {pclass}\", (x, y+h-50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 5)\n",
    "\n",
    "# Display the localized objects on the original image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.title('Localized Objects')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DQMeE4-o74BU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JYuV4g9273-3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIaG5jgS738L"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1713890006781,
     "user": {
      "displayName": "Rahat Parvej",
      "userId": "17759206363434202158"
     },
     "user_tz": -360
    },
    "id": "AH0DGmS8yQid"
   },
   "outputs": [],
   "source": [
    "test_samples=[]\n",
    "image = cv2.imread('/content/drive/MyDrive/Paddy Field/code/dataset/images/1705483831138.jpg')\n",
    "annotation_path = '/content/drive/MyDrive/Paddy Field/code/dataset/labels/1705483831138.txt'\n",
    "with open(annotation_path, 'r') as annotation_file:\n",
    "    lines = annotation_file.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        data = line.strip().split()\n",
    "        class_label = int(data[0])\n",
    "        x_center, y_center, width, height = map(float, data[1:5])\n",
    "\n",
    "\n",
    "        # Convert YOLO format to (x, y, w, h)\n",
    "        x = int((x_center - width / 2) * image.shape[1])\n",
    "        y = int((y_center - height / 2) * image.shape[0])\n",
    "        w = int(width * image.shape[1])\n",
    "        h = int(height * image.shape[0])\n",
    "\n",
    "        # Read the image and crop the region defined by the bounding box\n",
    "\n",
    "        cropped_image = image[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize the cropped region to the target size\n",
    "        resized_cropped_image = cv2.resize(cropped_image, target_size)\n",
    "\n",
    "        # Normalize pixel values to [0, 1]\n",
    "        normalized_cropped_image = resized_cropped_image / 255.0\n",
    "\n",
    "        # Append the training sample along with its class label\n",
    "        test_samples.append((normalized_cropped_image, class_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2455,
     "status": "ok",
     "timestamp": 1713891996222,
     "user": {
      "displayName": "Rahat Parvej",
      "userId": "17759206363434202158"
     },
     "user_tz": -360
    },
    "id": "hUS3hXAVzj-q"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained Xception model without the top classification layer\n",
    "base_model = Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add a localization head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(1, activation='sigmoid')(x)  # 4 output nodes for bounding box coordinates (xmin, ymin, xmax, ymax)\n",
    "\n",
    "\n",
    "localization_model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "error",
     "timestamp": 1713890695215,
     "user": {
      "displayName": "Rahat Parvej",
      "userId": "17759206363434202158"
     },
     "user_tz": -360
    },
    "id": "PumbXeYAzzZx",
    "outputId": "9667c48b-9742-435d-c89a-22a4b983df97"
   },
   "outputs": [],
   "source": [
    "# Load your trained model weights\n",
    "localization_model.load_weights('/content/drive/MyDrive/Paddy Field/code/xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B6E9YI5Fz9EJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOl5uF+0KFCSkE5uCnE4wH3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
